{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0851f07b-766b-4b2d-986e-4e7c67c6312c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Widgets"
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(name=\"env\", defaultValue=\"dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae7fae6a-37cd-4fb8-90f8-b9497a8ffe5d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "catalog = \"my_catalog\"\n",
    "env = schema = dbutils.widgets.get(\"env\")\n",
    "\n",
    "print(f\"env    : {env}\")\n",
    "print(f\"catalog: {catalog}\")\n",
    "print(f\"schema : {schema}\")\n",
    "\n",
    "products_tbl = f\"{catalog}.{schema}.products\"\n",
    "orders_tbl   = f\"{catalog}.{schema}.orders\"\n",
    "final_tbl    = f\"{catalog}.{schema}.orders_refined\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab2371a4-f312-4bbb-8895-030f94187ac0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "products_df = spark.table(products_tbl)\n",
    "orders_df   = spark.table(orders_tbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3707d22-4186-48cb-a957-d9f4b13bd0a7",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Imports"
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from src.helpers.utils import validate_dates_count, write_to_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "327d375d-e26f-4b1e-828e-4935ca5893a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "Cast order_date col as DATE type and check for any invalid dates in original df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa824d2e-acbe-47b4-abdf-d819b5cf99f9",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cast string to date in orders_df"
    }
   },
   "outputs": [],
   "source": [
    "orders_df = orders_df.withColumn(\n",
    "    \"order_date\",\n",
    "    F.col(\"order_date\").cast(\"date\")\n",
    ")\n",
    "\n",
    "invalid_count = validate_dates_count(orders_df, \"order_date\")\n",
    "if invalid_count > 0:\n",
    "    raise Exception(f\"Invalid date count: {invalid_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6bcd4849-6aa5-4d07-a123-2d0a4ca1e471",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Refined"
    }
   },
   "outputs": [],
   "source": [
    "orders_refined = (\n",
    "    orders_df\n",
    "    .dropDuplicates()\n",
    "    .join(products_df, on=\"product_id\", how=\"inner\")\n",
    "    .withColumn(\n",
    "        \"line_total\",\n",
    "        F.round(F.col(\"quantity\") * F.col(\"price\"), 2)\n",
    "    )\n",
    "    .withColumn(\"processed_at\", F.current_timestamp())\n",
    "    .select(\n",
    "        \"order_id\", \n",
    "        \"customer_id\", \n",
    "        \"product_id\", \n",
    "        \"product_name\", \n",
    "        \"category\", \n",
    "        \"quantity\", \n",
    "        \"price\", \n",
    "        \"line_total\", \n",
    "        \"order_date\", \n",
    "        \"processed_at\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0a7f9c1-17d6-477a-9431-756adc9caf98",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Write to refined table"
    }
   },
   "outputs": [],
   "source": [
    "write_query = \"\"\n",
    "\n",
    "if env in [\"stage\", \"prod\"]:\n",
    "    orders_refined.createOrReplaceTempView(\"orders_refined_vw\")\n",
    "    write_query = f\"\"\"\n",
    "            MERGE INTO \n",
    "                {final_tbl} AS t\n",
    "            USING \n",
    "                orders_refined_vw AS s\n",
    "                ON t.order_id = s.order_id\n",
    "            WHEN MATCHED THEN\n",
    "                UPDATE SET *\n",
    "            WHEN NOT MATCHED THEN\n",
    "                INSERT *\n",
    "            \"\"\"\n",
    "\n",
    "output = write_to_table(orders_refined, final_tbl, env, write_query)\n",
    "print(output)\n",
    "\n",
    "# TODO:\n",
    "# Change write mode and add options to experiment:\n",
    "#   1. mode    - overwrite, append\n",
    "#   2. options - mergeSchema, allowSchemaEvolution, overwriteSchema\n",
    "# How does merge query handle schema changes - new columns, data type change, renamed columns?"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02_transformations",
   "widgets": {
    "env": {
     "currentValue": "dev",
     "nuid": "6ad0c6d8-ca64-4959-8bd4-772b0c4d9855",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "dev",
      "label": null,
      "name": "env",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "dev",
      "label": null,
      "name": "env",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
